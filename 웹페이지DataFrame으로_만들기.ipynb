{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "웹페이지DataFrame으로 만들기.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObs5GAWm4qm2AaiIECFfCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyuna13/Data_Science/blob/master/%EC%9B%B9%ED%8E%98%EC%9D%B4%EC%A7%80DataFrame%EC%9C%BC%EB%A1%9C_%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLjtoufUQFjK"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import requests \n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "records = []\n",
        "\n",
        "page_num = 1\n",
        "\n",
        "headers = {'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36'} #headers 지정\n",
        "\n",
        "while True:\n",
        "    # HTML 코드 받아오기\n",
        "    response = requests.get(\"http://www.ssg.com/search.ssg?target=all&query=nintendo&page=\" + str(page_num), headers=headers)\n",
        "\n",
        "    # BeautifulSoup 타입으로 변형하기\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    #.prodName일때만 가져오기\n",
        "    if len(soup.select('.csrch_tip')) == 0:\n",
        "    product_names = soup.select('.cunit_info > div.cunit_md.notranslate > div > a > em.tx_ko')\n",
        "    product_prices = soup.select('.cunit_info > div.cunit_price.notranslate > div.opt_price > em')\n",
        "    product_urls = soup.select('.cunit_prod > div.thmb > a > img')\n",
        "    page_num += 1\n",
        "    time.sleep(3)\n",
        "        \n",
        "        # 상품의 정보를 하나의 레코드로 만들고, 리스트에 순서대로 추가하기\n",
        "        for i in range(len(product_names)):\n",
        "            record = []\n",
        "            record.append(product_names[i].text)\n",
        "            record.append(product_prices[i].text.strip())\n",
        "            record.append(\"https://www.ssg.com\" + product_urls[i].get('src'))\n",
        "            records.append(record)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# DataFrame 만들기\n",
        "df = pd.DataFrame(data = records, columns = [\"이름\", \"가격\", \"이미지 주소\"])\n",
        "\n",
        "# DataFrame 출력\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvoYz0N0YBhh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}